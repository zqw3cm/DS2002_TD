{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd0334a-4087-49bf-a2b8-c6d92aa0117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DS2002 Data Project 1\n",
    "# Teresa Duong\n",
    "# 10/20/2024\n",
    "\n",
    "# Modules Used:\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "#Note: I have run through my ETL processor multiple times through each combination of input and output in order to display the results of them all\n",
    "#in the cell outputs here. However, if the ETL processor is run only once, only the results related to the specified input and output will\n",
    "#run. Thank you!\n",
    "\n",
    "#To use this processor, please run each cell. Input directions will be printed, additional notes on the program will be in comments, and \n",
    "#rubric criteria will be quoted in comments. Thank you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "af90271b-9073-4e1e-8e7b-64d1049056fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which data source would you like to process first? Please type 'CSV' for the Charlottesville Transit CSV dataset or 'JSON' for the Nobel Peace Prize Winners JSON dataset.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " JSON\n"
     ]
    }
   ],
   "source": [
    "print (\"Which data source would you like to process first? Please type 'CSV' for the Charlottesville Transit CSV dataset or 'JSON' for the Nobel Peace Prize Winners JSON dataset.\")\n",
    "input_data_type = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9e469222-c02e-4e52-a8b4-1372a7d388e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please name the output format you would like your data source in (For CSV input, there are JSON and SQL options, for JSON input there are CSV and SQL options)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " SQL\n"
     ]
    }
   ],
   "source": [
    "print(\"Please name the output format you would like your data source in (For CSV input, there are JSON and SQL options, for JSON input there are CSV and SQL options)\")\n",
    "output_data_type = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7d1cf7e0-1add-4463-a213-7a287dc6aaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confirmation: The file we will process is DataSource_2_Nobel_Peace_Prize_Winners.json\n"
     ]
    }
   ],
   "source": [
    "# File Confirmation: A printed message will confirm what file we are processing.\n",
    "if input_data_type == 'CSV':\n",
    "    filename = \"DataSource_1_Transit_2020.csv\"\n",
    "    print(f' Confirmation: The file we will process is {filename}')    \n",
    "elif input_data_type == 'JSON':\n",
    "    filename = \"DataSource_2_Nobel_Peace_Prize_Winners.json\"\n",
    "    print(f' Confirmation: The file we will process is {filename}')\n",
    "else:\n",
    "    print(\"Error: Invalid input file format. Please type either 'CSV' or 'JSON'. Thank you.\")\n",
    "\n",
    "# Both data sources are local files in the folder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "060c9d7d-41c8-470f-bd23-2dbc51b4a4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Records: 1012\n",
      "Number of Columns: 7\n",
      "Preview of First 3 Objects:\n",
      "[\n",
      "    {\n",
      "        \"id\": \"1039\",\n",
      "        \"firstname\": \"David\",\n",
      "        \"surname\": \"Baker\",\n",
      "        \"motivation\": \"\\\"for computational protein design\\\"\",\n",
      "        \"share\": \"2\",\n",
      "        \"year\": \"2024\",\n",
      "        \"category\": \"chemistry\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"1040\",\n",
      "        \"firstname\": \"Demis\",\n",
      "        \"surname\": \"Hassabis\",\n",
      "        \"motivation\": \"\\\"for protein structure prediction\\\"\",\n",
      "        \"share\": \"4\",\n",
      "        \"year\": \"2024\",\n",
      "        \"category\": \"chemistry\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"1041\",\n",
      "        \"firstname\": \"John\",\n",
      "        \"surname\": \"Jumper\",\n",
      "        \"motivation\": \"\\\"for protein structure prediction\\\"\",\n",
      "        \"share\": \"4\",\n",
      "        \"year\": \"2024\",\n",
      "        \"category\": \"chemistry\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# \"Fetch / download / retrieve a remote data file by URL, or ingest a local file mounted.\" \n",
    "# (Both data sources are local files in the submitted folder)\n",
    "\n",
    "\n",
    "# \"In your code, Generate a brief summary of the data file ingestion including:\n",
    "# 1. Number of records\n",
    "# 2. Number of columns\"\n",
    "\n",
    "if input_data_type == 'CSV':\n",
    "    records = []\n",
    "    columns = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        columns = next(csvreader)\n",
    "        for record in csvreader:\n",
    "            records.append(record)\n",
    "        print(\"Number of Records: %d\" % (len(records)))\n",
    "        print(\"Number of Columns: %d\" % len(columns))\n",
    "    print(\"Preview of First 3 Records:\")\n",
    "    display(pd.read_csv(filename).head(3))\n",
    "\n",
    "#I created lists containing the records and column names. I counted the numbers of each by finding the length of these lists.\n",
    "        \n",
    "elif input_data_type == 'JSON':\n",
    "    with open(filename, 'r') as jsonfile:\n",
    "        data = json.load(jsonfile)\n",
    "        flattened_data = []     #My json file was nested, so I flattened it by adding the larger nest keys to each laureate object individually.   \n",
    "        for prize in data['prizes']:\n",
    "            year = prize['year']\n",
    "            category = prize['category']            \n",
    "            for laureate in prize.get('laureates', []):\n",
    "                laureate['year'] = year\n",
    "                laureate['category'] = category\n",
    "                flattened_data.append(laureate) \n",
    "        print(\"Number of Records: %d\" % len(flattened_data))\n",
    "        print(\"Number of Columns: %d\" % len(flattened_data[0].keys())) \n",
    "        print(\"Preview of First 3 Objects:\")\n",
    "        print(json.dumps(flattened_data[:3], indent=4))\n",
    "\n",
    "#I flattened my json file in order to count the record and columns, and also to prepare it for conversion to CSV and SQL table formats later on.\n",
    "#I counted the number of records by finding the length/number of objects in my flattened data structure.\n",
    "#I counted the number of columns by finding the length/number of keys in the first object, since all objects in this dataset have the same keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9fc81ed7-30aa-45ee-9799-dd69fb6e17ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in modified JSON: 1012\n",
      "Number of columns in modified JSON: 6\n",
      "Preview of first 3 objects:\n",
      "[\n",
      "    {\n",
      "        \"id\": \"1039\",\n",
      "        \"firstname\": \"David\",\n",
      "        \"surname\": \"Baker\",\n",
      "        \"share\": \"2\",\n",
      "        \"year\": \"2024\",\n",
      "        \"category\": \"chemistry\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"1040\",\n",
      "        \"firstname\": \"Demis\",\n",
      "        \"surname\": \"Hassabis\",\n",
      "        \"share\": \"4\",\n",
      "        \"year\": \"2024\",\n",
      "        \"category\": \"chemistry\"\n",
      "    },\n",
      "    {\n",
      "        \"id\": \"1041\",\n",
      "        \"firstname\": \"John\",\n",
      "        \"surname\": \"Jumper\",\n",
      "        \"share\": \"4\",\n",
      "        \"year\": \"2024\",\n",
      "        \"category\": \"chemistry\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# \"Modify the number of columns from the source to the destination, reducing or adding columns. If you add data cols you can put any other\n",
    "# useful information in that column you wish\"\n",
    "\n",
    "if input_data_type == 'CSV':\n",
    "    with open(filename, 'r') as csvfile, open('modified_transit.csv', 'w') as modified_csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        writer = csv.writer(modified_csvfile)\n",
    "        columns = next(csvreader)\n",
    "        remove_column = 'Fare'\n",
    "#The Charlottesville Transit system has discontinued the use of fares to admit passengers since 2020, so I chose to remove this column since it is \n",
    "#less relevant today.\n",
    "        column_to_remove_index = columns.index(remove_column)\n",
    "        modified_columns = [col for i, col in enumerate(columns) if i != column_to_remove_index]\n",
    "        writer.writerow(modified_columns)\n",
    "        modified_records = []  \n",
    "        for record in csvreader:\n",
    "            modified_record = [value for i, value in enumerate(record) if i != column_to_remove_index]\n",
    "            writer.writerow(modified_record)  # Write the modified row to the new CSV file\n",
    "            modified_records.append(record)\n",
    "# \"In your code Generate a brief summary of the post processing including:\n",
    "#1. Number of records\n",
    "#2. Number of columns\"\n",
    "        print(\"Number of records in modified CSV: %d\" % len(modified_records))\n",
    "        print(\"Number of columns in modified CSV: %d\" % len(modified_columns))\n",
    "        print(\"Preview of first 3 records:\")\n",
    "        display(pd.read_csv('modified_transit.csv').head(3))\n",
    "\n",
    "elif input_data_type == 'JSON':\n",
    "    with open('modified_nobel.json', 'w') as modified_jsonfile:\n",
    "        modified_flattened_data = []\n",
    "        for laureate in flattened_data:\n",
    "            laureate.pop('motivation', None) # I removed the 'motivation' column since the column values had a string of text datatype which could allow for more variance, less normalization.\n",
    "            modified_flattened_data.append(laureate)\n",
    "        json.dump(flattened_data, modified_jsonfile, indent=4)\n",
    "# \"In your code Generate a brief summary of the post processing including:\n",
    "#1. Number of records\n",
    "#2. Number of columns\"\n",
    "        print(\"Number of records in modified JSON: %d\" % len(flattened_data))\n",
    "        print(\"Number of columns in modified JSON: %d\" % len(flattened_data[0].keys()))\n",
    "        print(\"Preview of first 3 objects:\")\n",
    "        print(json.dumps(flattened_data[:3], indent=4))\n",
    "else:\n",
    "    print(\"Error: Invalid output file format. Please type either 'CSV', 'JSON', or 'SQL'. Thank you.\")\n",
    "\n",
    "#To remove a column from the Transit CSV dataset, I wrote to a new CSV only rows and columns that do NOT have column = 'Fare'.\n",
    "#To remove a column from the Nobel Peace Prize Winners JSON dataset, used the pop() method to remove the column 'motivation' and appended the modified\n",
    "#objects to modified_flattened_data. I dumped this data into a new JSON file.\n",
    "#I used similar methods as in the previous cell to count the number of records and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "15032d29-2e06-4b95-9925-026667eaf18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of first 3 records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransitID</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Route</th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Count</th>\n",
       "      <th>FareCategory</th>\n",
       "      <th>PaymentType</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2453</td>\n",
       "      <td>10472 - Emmet St at Central Grounds Please ref...</td>\n",
       "      <td>07 A</td>\n",
       "      <td>2020/01/18 17:09:00+00</td>\n",
       "      <td>1</td>\n",
       "      <td>UVA Academic</td>\n",
       "      <td>Barcode-3rd Party Media</td>\n",
       "      <td>38.0363</td>\n",
       "      <td>-78.5078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2454</td>\n",
       "      <td>10472 - Emmet St at Central Grounds Please ref...</td>\n",
       "      <td>07 A</td>\n",
       "      <td>2020/01/18 17:09:00+00</td>\n",
       "      <td>1</td>\n",
       "      <td>UVA Academic</td>\n",
       "      <td>Barcode-3rd Party Media</td>\n",
       "      <td>38.0363</td>\n",
       "      <td>-78.5078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransitID                                               Stop Route  \\\n",
       "0       2453  10472 - Emmet St at Central Grounds Please ref...  07 A   \n",
       "1       2454  10472 - Emmet St at Central Grounds Please ref...  07 A   \n",
       "\n",
       "                Date_Time  Count  FareCategory              PaymentType  \\\n",
       "0  2020/01/18 17:09:00+00      1  UVA Academic  Barcode-3rd Party Media   \n",
       "1  2020/01/18 17:09:00+00      1  UVA Academic  Barcode-3rd Party Media   \n",
       "\n",
       "   Latitude  Longitude  \n",
       "0   38.0363   -78.5078  \n",
       "1   38.0363   -78.5078  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \"Convert the general format and data structure of the data source (from JSON to CSV, from CSV to JSON, from JSON into a SQL database table, etc.)\"\n",
    "# \"I want the option to convert any source to any target. So, if I get a CSV as an input, I want the user to choose an output\"\n",
    "\n",
    "#Convert CSV to Dataframe Initially\n",
    "if input_data_type == 'CSV':\n",
    "    transit_df = pd.read_csv(\"modified_transit.csv\")\n",
    "    print(\"Preview of first 3 records:\")\n",
    "    display(transit_df.head(2))\n",
    "\n",
    "#This cell will run if the user has chosen a CSV file to process. \n",
    "#I chose to convert the CSV to a panda dataframe first so that it can be used in both JSON and SQL table conversions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "800ac32b-eb74-4917-872b-0a86a0129f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of First 3 Objects of Modified Transit JSON file:\n",
      "[\n",
      "    {\n",
      "        \"TransitID\": 2453,\n",
      "        \"Stop\": \"10472 - Emmet St at Central Grounds Please refer to the Latitude/Longitude for location\",\n",
      "        \"Route\": \"07 A\",\n",
      "        \"Date_Time\": \"2020/01/18 17:09:00+00\",\n",
      "        \"Count\": 1,\n",
      "        \"FareCategory\": \"UVA Academic\",\n",
      "        \"PaymentType\": \"Barcode-3rd Party Media\",\n",
      "        \"Latitude\": 38.0363,\n",
      "        \"Longitude\": -78.5078\n",
      "    },\n",
      "    {\n",
      "        \"TransitID\": 2454,\n",
      "        \"Stop\": \"10472 - Emmet St at Central Grounds Please refer to the Latitude/Longitude for location\",\n",
      "        \"Route\": \"07 A\",\n",
      "        \"Date_Time\": \"2020/01/18 17:09:00+00\",\n",
      "        \"Count\": 1,\n",
      "        \"FareCategory\": \"UVA Academic\",\n",
      "        \"PaymentType\": \"Barcode-3rd Party Media\",\n",
      "        \"Latitude\": 38.0363,\n",
      "        \"Longitude\": -78.5078\n",
      "    },\n",
      "    {\n",
      "        \"TransitID\": 2455,\n",
      "        \"Stop\": \"10472 - Emmet St at Central Grounds Please refer to the Latitude/Longitude for location\",\n",
      "        \"Route\": \"07 A\",\n",
      "        \"Date_Time\": \"2020/01/18 17:09:00+00\",\n",
      "        \"Count\": 1,\n",
      "        \"FareCategory\": \"UVA Academic\",\n",
      "        \"PaymentType\": \"Barcode-3rd Party Media\",\n",
      "        \"Latitude\": 38.0363,\n",
      "        \"Longitude\": -78.5078\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#Convert Dataframe --> JSON\n",
    "if input_data_type == 'CSV' and output_data_type == 'JSON':\n",
    "    with open('transit_json_conversion.json', 'w') as jsonfile:\n",
    "        transit_json = transit_df.to_json(orient='records', indent=4)\n",
    "        transit_deserialized = json.loads(transit_json)\n",
    "        json.dump(transit_deserialized, jsonfile, indent=4)\n",
    "        print (\"Preview of First 3 Objects of Modified Transit JSON file:\")\n",
    "        print(json.dumps(transit_deserialized[:3], indent=4))\n",
    "#If the user has specified both an input of CSV and an output of JSON, this cell will run.\n",
    "#To covert the dataframe we made in the previous cell, I used the .to_json method.\n",
    "#In order to display a previw of the first 3 objects, I converted the JSON to Python and called the first three objects.\n",
    "#To store the converted new file, I wrote the JSON data structure to transit_json_conversion.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "721d713d-2987-4bb0-9133-95e2c584275a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of First 3 Rows of Modified Transit SQL Table:\n",
      "Header: ['TransitID', 'Stop', 'Route', 'Date_Time', 'Count', 'FareCategory', 'PaymentType', 'Latitude', 'Longitude']\n",
      "(2453, '10472 - Emmet St at Central Grounds Please refer to the Latitude/Longitude for location', '07 A', '2020/01/18 17:09:00+00', 1, 'UVA Academic', 'Barcode-3rd Party Media', 38.0363, -78.5078)\n",
      "(2454, '10472 - Emmet St at Central Grounds Please refer to the Latitude/Longitude for location', '07 A', '2020/01/18 17:09:00+00', 1, 'UVA Academic', 'Barcode-3rd Party Media', 38.0363, -78.5078)\n",
      "(2455, '10472 - Emmet St at Central Grounds Please refer to the Latitude/Longitude for location', '07 A', '2020/01/18 17:09:00+00', 1, 'UVA Academic', 'Barcode-3rd Party Media', 38.0363, -78.5078)\n"
     ]
    }
   ],
   "source": [
    "# Convert Dataframe --> SQL Table\n",
    "if input_data_type == 'CSV' and output_data_type == 'SQL':\n",
    "    Path(\"transit_sql_conversion.db\").touch()\n",
    "    connection =sqlite3.connect(\"transit_sql_conversion.db\")\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    transit_df.to_sql('transit_table', connection, if_exists='replace', index=False)\n",
    "\n",
    "    #Preview of First 3 Rows\n",
    "    print(\"Preview of First 3 Rows of Modified Transit SQL Table:\")\n",
    "    cursor.execute(\"SELECT * FROM transit_table LIMIT 3\")\n",
    "    column_names = [description[0] for description in cursor.description]\n",
    "    print(\"Header:\", column_names)\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "    \n",
    "    connection.close()\n",
    "#I first created a new database \"transit_sql_conversion.db\" and connected to it.\n",
    "#I then used the to_sql() method to convert the dataframe we made two cells above into a SQL table.\n",
    "#To preview the first 3 rows of the table, I used SELECT and printed each row I selected as well as the column names (Header). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6a6f9073-a531-4be5-a60d-ba7769bf11bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of first 3 records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>firstname</th>\n",
       "      <th>surname</th>\n",
       "      <th>share</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1039</td>\n",
       "      <td>David</td>\n",
       "      <td>Baker</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1040</td>\n",
       "      <td>Demis</td>\n",
       "      <td>Hassabis</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041</td>\n",
       "      <td>John</td>\n",
       "      <td>Jumper</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id firstname   surname share  year   category\n",
       "0  1039     David     Baker     2  2024  chemistry\n",
       "1  1040     Demis  Hassabis     4  2024  chemistry\n",
       "2  1041      John    Jumper     4  2024  chemistry"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert JSON --> Dataframe Initially\n",
    "if input_data_type == 'JSON':\n",
    "    with open('modified_nobel.json', 'r') as jsonfile:\n",
    "        nobel_data = json.load(jsonfile)\n",
    "        nobel_df = pd.DataFrame(nobel_data)\n",
    "        print(\"Preview of first 3 records:\")\n",
    "        display(nobel_df.head(3))\n",
    "#Similarly, for user requests to process a JSON file, I initially converted the JSON to a panda dataframe to prepare it for CSV and SQL table conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4a5ecc26-2558-4c94-8146-5faa7a8733ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of first 3 records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>firstname</th>\n",
       "      <th>surname</th>\n",
       "      <th>share</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1039</td>\n",
       "      <td>David</td>\n",
       "      <td>Baker</td>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1040</td>\n",
       "      <td>Demis</td>\n",
       "      <td>Hassabis</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041</td>\n",
       "      <td>John</td>\n",
       "      <td>Jumper</td>\n",
       "      <td>4</td>\n",
       "      <td>2024</td>\n",
       "      <td>chemistry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id firstname   surname  share  year   category\n",
       "0  1039     David     Baker      2  2024  chemistry\n",
       "1  1040     Demis  Hassabis      4  2024  chemistry\n",
       "2  1041      John    Jumper      4  2024  chemistry"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert Dataframe --> CSV\n",
    "if input_data_type == 'JSON' and output_data_type == 'CSV':\n",
    "    nobel_df.to_csv('nobel_csv_conversion.csv', index=False)\n",
    "    print(\"Preview of first 3 records:\")\n",
    "    display(pd.read_csv('nobel_csv_conversion.csv').head(3))\n",
    "#I used the .to_csv() method to convert the dataframe we made in the previous cell into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a6f2dbd2-e51d-42ea-a778-6b4191ac693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A preview of the first 3 rows:\n",
      "Header: ['id', 'firstname', 'surname', 'share', 'year', 'category']\n",
      "('1039', 'David', 'Baker', '2', '2024', 'chemistry')\n",
      "('1040', 'Demis', 'Hassabis', '4', '2024', 'chemistry')\n",
      "('1041', 'John', 'Jumper', '4', '2024', 'chemistry')\n"
     ]
    }
   ],
   "source": [
    "# Convert Dataframe --> SQL\n",
    "if input_data_type == 'JSON' and output_data_type == 'SQL':\n",
    "    Path(\"nobel_sql_conversion.db\").touch()\n",
    "    connection =sqlite3.connect(\"nobel_sql_conversion.db\")\n",
    "    cursor = connection.cursor()\n",
    "    \n",
    "    nobel_df.to_sql('nobel_table', connection, if_exists='replace', index=False)\n",
    "\n",
    "    # Preview of First 5 Rows in SQL Table:\n",
    "    print(\"A preview of the first 3 rows:\")\n",
    "    cursor.execute(\"SELECT * FROM nobel_table LIMIT 3\")\n",
    "    column_names = [description[0] for description in cursor.description]\n",
    "    print(\"Header:\", column_names)\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "    \n",
    "    connection.close()\n",
    "#Similarly to our CSV --> SQL conversion, I first created a new database \"nobel_sql_conversion\" and connected to it.\n",
    "#I then created a table within the database, \"nobel_table\"\n",
    "#To preview the first 3 rows of the table, I used SELECT and printed each row I selected as well as the column names (Header). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "54507fd7-dc55-4332-b8ad-1871be3a4241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The path to the new stored SQL database:\n",
      "C:\\Users\\13012\\OneDrive - University of Virginia\\3rd Year 24-25\\Data Science Systems\\Project 1\\nobel_sql_conversion.db\n"
     ]
    }
   ],
   "source": [
    "# \"Store The converted (new) file should be written to disk (local file) or written to a SQL database.\"\n",
    "if input_data_type == 'CSV' and output_data_type == 'JSON':\n",
    "    print(\"The path to the new stored JSON file:\")\n",
    "    transit_json_path = Path('transit_json_conversion.json').resolve()\n",
    "    print(transit_json_path)\n",
    "elif input_data_type == 'CSV' and output_data_type == 'SQL':\n",
    "    print(\"The path to the new stored SQL database:\")\n",
    "    transit_db_path = Path(\"transit_sql_conversion.db\").resolve()\n",
    "    print(transit_db_path)\n",
    "elif input_data_type == 'JSON' and output_data_type == 'CSV':\n",
    "    print(\"The path to the new stored CSV file:\")\n",
    "    transit_db_path = Path('nobel_csv_conversion.csv').resolve()\n",
    "    print(transit_db_path)\n",
    "elif input_data_type == 'JSON' and output_data_type == 'SQL':\n",
    "    print(\"The path to the new stored SQL database:\")\n",
    "    transit_db_path = Path(\"nobel_sql_conversion.db\").resolve()\n",
    "    print(transit_db_path)\n",
    "\n",
    "#Here I provided the paths to all created files to show that I have I locally stored our converted (new) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2f13708c-d227-4213-8f00-9cbe7b62cc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using this processor! Please clear outputs and return to cell 1 to process another file or receive a different format output. Have a wonderful day!\n"
     ]
    }
   ],
   "source": [
    "print(\"Thank you for using this processor! Please clear outputs and return to cell 1 to process another file or receive a different format output. Have a wonderful day!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
